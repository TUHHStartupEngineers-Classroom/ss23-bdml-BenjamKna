{
  "hash": "d30090060c50fba1ca3dccd5f13999e5",
  "result": {
    "markdown": "---\ntitle: \"Challenge 5 \"\nauthor: \"Benjamin Knaack\"\ndate: \"2023-05-21\"\noutput: html_document\n---\n\n\n\n\n\n### Challenge 5: Apply all the steps you have learned in this session on the dataset from challenge of the last session (Product Backorders):\n\n\nIn this challenge I didn't manage to render the website with the eval attributes in the code chunks as TRUE. Thus I set eval to FALSE and included the images generated by my R file underneath each code chunk.\nMy solution is based on my solution from challenge 4. So I included the code for challenge 4 for the sake of completeness.\n\n\n\nFrom challenge 4:\n\n\n::: {.cell hash='05_challenge_cache/html/unnamed-chunk-1_a76597cdb79f03524794a4f588b65ec2'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rsample)\nlibrary(h2o)\nlibrary(recipes)\n\n\n# Step 1 - Load the training & test dataset\nproduct_backorders_tbl <- read_csv(\"~/Documents/GitHub/ss23-bdml-BenjamKna/product_backorders.csv\")\n\nset.seed(seed = 3030)\nsplit_obj <- rsample::initial_split(product_backorders_tbl, prop = 0.85)\ntrain_tbl <- training(split_obj)\ntest_tbl <- testing(split_obj)\n\n\n\n# Step 2 - Specifiy the response and predictor variables\n\nrecipe_obj <- recipe(went_on_backorder ~., data = train_tbl) %>% \n  step_zv(all_predictors()) %>% \n  step_mutate_at(names(train_tbl)[train_tbl %>% sapply(is.character)], fn = as.factor) %>% \n  prep()\n\ntrain_tbl <- bake(recipe_obj, new_data = train_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_tbl)\n\n\n# Modeling\nh2o.init()\n\n# Split data into a training and a validation data frame\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl) # Leaderboard Frame\n\n\ny <- \"went_on_backorder\" # response variable\nx <- setdiff(names(train_h2o), y) # predictor \n\n\n# Step 3 - run AutoML specifying the stopping criterion\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 60,\n  nfolds            = 5 \n)\n\n\n\n# Step 4 - View the leaderboard\n\n# The leaderboard is a summary of the models produced by H2O AutoML\n\nview(automl_models_h2o@leaderboard)\n\nslotNames(automl_models_h2o)\n\n\n# Step 5 - Predicting using Leader Model\n\npredictions <- h2o.predict(automl_models_h2o@leader, newdata = as.h2o(test_tbl))\n\npredictions_tbl <- predictions %>% as_tibble()\n\n\n\n# Step 6 - Save the leader model\n\nh2o.saveModel(automl_models_h2o@leader,path = \"~/Documents/GitHub/ss23-bdml-BenjamKna/04_Modeling/h20_models/\")\n```\n:::\n\n\n\n#### Step 1 - Leaderboard visualization\n\n\n::: {.cell hash='05_challenge_cache/html/unnamed-chunk-2_925804a542ec18d4056f23f21a57d8eb'}\n\n```{.r .cell-code}\n# Function for viz of the leaderboard (from business case) \nsource(\"~/Documents/GitHub/ss23-bdml-BenjamKna/plot_h2o_leaderboard.R\")\n\nplot_h2o_leaderboard(automl_models_h2o@leaderboard,order_by = \"auc\", size = 7, include_lbl = TRUE)\n```\n:::\n\n![](img_chal5/step1_large.png)\n\n\n#### Step 2 - Tune a model with grid search\nI actually managed to increase the accuracy of a deeplearning model generated by automl from 88% to 90%.\nI just took the paremeters epochs and hidden with the same values as from the business case.\n\n\n::: {.cell hash='05_challenge_cache/html/unnamed-chunk-3_f545d943ec74934edde58793a1965b67'}\n\n```{.r .cell-code}\ndeeplearning_h2o <- h2o.getModel(\"DeepLearning_1_AutoML_12_20230520_180101\")\n# create h2o performance object\nperformance_h2o <- h2o.performance(deeplearning_h2o, newdata = as.h2o(test_tbl)) # maximum accuracy: 88%\n\n#deeplearning_h2o@allparameters\n\n\n# code snippet taken from business case\ndeeplearning_grid_01 <- h2o.grid(\n  \n  # See help page for available algos\n  algorithm = \"deeplearning\",\n  \n  # I just use the same as the object\n  grid_id = \"deeplearning_grid_01\",\n  \n  # The following is for ?h2o.deeplearning()\n  # predictor and response variables\n  x = x,\n  y = y,\n  \n  # training and validation frame and crossfold validation\n  training_frame   = train_h2o,\n  validation_frame = valid_h2o,\n  nfolds = 5,\n  \n  # Hyperparamters: Use deeplearning_h2o@allparameters to see all\n  hyper_params = list(\n    # Use some combinations (the first one was the original)\n    hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)),\n    epochs = c(10, 50, 100)\n  )\n)\n\nh2o.getGrid(grid_id = \"deeplearning_grid_01\", sort_by = \"auc\", decreasing = TRUE)\n\n# deeplearning_grid_01_model_29 has the best AUC\n\ndeeplearning_grid_01_model_29 <- h2o.getModel(\"deeplearning_grid_01_model_29\")\n# xval auc = 0.86\n\ndeeplearning_grid_01_model_29 %>% h2o.auc(train = T, valid = T, xval = T)\n# the difference between training AUC (0.89) and validation AUC (0.901) is not to large.\n\n\nh2o.performance(deeplearning_grid_01_model_29, newdata = as.h2o(test_tbl))\n\n# max accuracy increased to 90.3 % (previously it was 88 %)\n```\n:::\n\n\n#### Step 3 - Visualize the trade of between the precision and the recall and the optimal threshold\n\nThis refers to the deeplearning model before tuning with grid search. \n\n\n::: {.cell hash='05_challenge_cache/html/unnamed-chunk-4_732004b56e52d9233c0a5a02bd90bb3f'}\n\n```{.r .cell-code}\n# precision measures false positive: predicted to be put on backorder but wasn't\n# recall measures false negatives: predicted to be not be put on backorder but was.\n\ntheme_new <- theme(\n  legend.position  = \"bottom\",\n  legend.key       = element_blank(),\n  panel.background = element_rect(fill   = \"transparent\"),\n  panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n  panel.grid.major = element_line(color = \"grey\", size = 0.333)\n) \n\nperformance_tbl <- performance_h2o %>%\n  h2o.metric() %>%\n  as.tibble() \n\n\nperformance_tbl %>%\n  ggplot(aes(x = threshold)) +\n  geom_line(aes(y = precision), color = \"blue\", size = 1) +\n  geom_line(aes(y = recall), color = \"red\", size = 1) +\n  \n  # Insert line where precision and recall are harmonically optimized\n  geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o, \"f1\")) +\n  labs(title = \"Precision vs Recall\", y = \"value\") +\n  theme_new\n```\n:::\n\n\n![](img_chal5/img_chal5_step3.png)\n\n\n#### Step 4 - ROC Plot\n\nI visualized the performance increase by tuning the deeplearning model delivered by automl with with gridsearch. Obviously the tuned model does a much better job. \n\n\n\n::: {.cell hash='05_challenge_cache/html/unnamed-chunk-5_ec64cc9bf5c6413892f974ebf7aaa41d'}\n\n```{.r .cell-code}\n# place models in folder\n\n  h2o.saveModel(deeplearning_grid_01_model_29,path = \"~/Documents/GitHub/ss23-bdml-BenjamKna/05_chal/h20_models/\")\n  h2o.saveModel(deeplearning_h2o, path = \"~/Documents/GitHub/ss23-bdml-BenjamKna/05_chal/h20_models/\")\n  \n\nload_model_performance_metrics <- function(path, test_tbl) {\n  \n  model_h2o <- h2o.loadModel(path)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc)\n  \n}\n\nmodel_metrics_tbl <- fs::dir_info(path=\"~/Documents/GitHub/ss23-bdml-BenjamKna/05_chal/h20_models/\") %>%\n  select(path) %>%\n  mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%\n  unnest(cols = metrics)\n\n\nmodel_metrics_tbl %>%\n  mutate(\n    # Extract the model names\n    path = str_split(path, pattern = \"/\", simplify = T)[,3] %>% as_factor(),\n    auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(fpr, tpr, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  \n  # just for demonstration purposes\n  geom_abline(color = \"red\", linetype = \"dotted\") +\n  \n  theme_new +\n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"ROC Plot\",\n    subtitle = \"Performance of model tuned with grid search vs. delivered as is by automl function\"\n  )\n```\n:::\n\n\n![](img_chal5/img_chal5_step4.png)\n\n#### Step 5 - Precision vs Recall Plot\n\n\n::: {.cell hash='05_challenge_cache/html/unnamed-chunk-6_868ada1988ea4b78e423c95970d529cc'}\n\n```{.r .cell-code}\nload_model_performance_metrics <- function(path, test_tbl) {\n  \n  model_h2o <- h2o.loadModel(path)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc, precision, recall)\n  \n}\n\nmodel_metrics_tbl <- fs::dir_info(path = \"~/Documents/GitHub/ss23-bdml-BenjamKna/05_chal/h20_models/\") %>%\n  select(path) %>%\n  mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%\n  unnest(cols = metrics)\n\nmodel_metrics_tbl %>%\n  mutate(\n    path = str_split(path, pattern = \"/\", simplify = T)[,3] %>% as_factor(),\n    auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(recall, precision, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  theme_new + \n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"Precision vs Recall Plot\",\n    subtitle = \"Performance of model tuned with grid search vs. delivered as is by automl function\"\n  )\n```\n:::\n\n\n\n![](img_chal5/img_chal5_step5.png)\n\n#### Step 6 - Gain Plot\n\n\n::: {.cell hash='05_challenge_cache/html/unnamed-chunk-7_90b909422b94ecbab66050888f2ec6c8'}\n\n```{.r .cell-code}\ngain_lift_tbl <- performance_h2o %>%\n  h2o.gainsLift() %>%\n  as.tibble()\n\n## Gain Chart\n\ngain_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"lift\")) %>%\n  mutate(baseline = cumulative_data_fraction) %>%\n  rename(gain     = cumulative_capture_rate) %>%\n  # prepare the data for the plotting (for the color and group aesthetics)\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\ngain_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Gain Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Gain\"\n  ) +\n  theme_new\n\n\n\n\n\ngain_lift_tbl <- performance_h2o %>%\n  h2o.gainsLift() %>%\n  as.tibble()\n\n## Gain Chart\n\ngain_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"lift\")) %>%\n  mutate(baseline = cumulative_data_fraction) %>%\n  rename(gain     = cumulative_capture_rate) %>%\n  # prepare the data for the plotting (for the color and group aesthetics)\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\ngain_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Gain Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Gain\"\n  ) +\n  theme_new\n```\n:::\n\n\n\n![](img_chal5/img_chal5_step6.png)\n\n#### Step 7 - Lift Plot\n\n\n::: {.cell hash='05_challenge_cache/html/unnamed-chunk-8_5c3812e1d0b43092b5ed151169db4906'}\n\n```{.r .cell-code}\nlift_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"capture\")) %>%\n  mutate(baseline = 1) %>%\n  rename(lift = cumulative_lift) %>%\n  pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n\nlift_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Lift Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Lift\"\n  ) +\n  theme_new\n```\n:::\n\n\n![](img_chal5/img_chal5_step7.png)\n\n\n#### Step 8 - Dashboard with cowplot\n\nThis refers to the best 3 models delivered by automl.\n\n\n::: {.cell hash='05_challenge_cache/html/unnamed-chunk-9_d4acdfb1f4f73b01e3126522a21ad319'}\n\n```{.r .cell-code}\nlibrary(cowplot)\nlibrary(glue)\n\n\n# set values to test the function while building it\nh2o_leaderboard <- automl_models_h2o@leaderboard\nnewdata <- test_tbl\norder_by <- \"auc\"\nmax_models <- 4\nsize <- 1\n\nplot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n  \n  # Inputs\n  \n  leaderboard_tbl <- h2o_leaderboard %>%\n    as_tibble() %>%\n    slice(1:max_models)\n  \n  newdata_tbl <- newdata %>%\n    as_tibble()\n  \n  # Selecting the first, if nothing is provided\n  order_by      <- tolower(order_by[[1]]) \n  \n  # Convert string stored in a variable to column name (symbol)\n  order_by_expr <- rlang::sym(order_by)\n  \n  # Turn of the progress bars ( opposite h2o.show_progress())\n  h2o.no_progress()\n  \n  # 1. Model metrics\n  \n  get_model_performance_metrics <- function(model_id, test_tbl) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl))\n    \n    perf_h2o %>%\n      h2o.metric() %>%\n      as.tibble() %>%\n      select(threshold, tpr, fpr, precision, recall)\n    \n  }\n  \n  model_metrics_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        # programmatically reorder factors depending on order_by\n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc      = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss  = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    )\n  \n  \n  # 1A. ROC Plot\n  \n  p1 <- model_metrics_tbl %>%\n    ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n    theme(legend.direction = \"vertical\") \n  \n  \n  # 1B. Precision vs Recall\n  \n  p2 <- model_metrics_tbl %>%\n    ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n    theme(legend.position = \"none\") \n  \n  \n  # 2. Gain / Lift\n  \n  get_gain_lift <- function(model_id, test_tbl) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n    \n    perf_h2o %>%\n      h2o.gainsLift() %>%\n      as.tibble() %>%\n      select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n    \n  }\n  \n  gain_lift_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc  = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    ) %>%\n    rename(\n      gain = cumulative_capture_rate,\n      lift = cumulative_lift\n    ) \n  \n  # 2A. Gain Plot\n  \n  p3 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, gain, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size,) +\n    geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Gain\",\n         x = \"Cumulative Data Fraction\", y = \"Gain\") +\n    theme(legend.position = \"none\")\n  \n  # 2B. Lift Plot\n  \n  p4 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, lift, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Lift\",\n         x = \"Cumulative Data Fraction\", y = \"Lift\") +\n    theme(legend.position = \"none\") \n  \n  \n  # Combine using cowplot\n  \n  # cowplot::get_legend extracts a legend from a ggplot object\n  p_legend <- get_legend(p1)\n  # Remove legend from p1\n  p1 <- p1 + theme(legend.position = \"none\")\n  \n  # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n  p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n  \n  # cowplot::ggdraw() sets up a drawing layer\n  p_title <- ggdraw() + \n    \n    # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n    draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n               color = \"#2C3E50\")\n  \n  p_subtitle <- ggdraw() + \n    draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n               color = \"#2C3E50\")\n  \n  # Combine everything\n  ret <- plot_grid(p_title, p_subtitle, p, p_legend, \n                   \n                   # Adjust the relative spacing, so that the legends always fits\n                   ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n  \n  h2o.show_progress()\n  \n  return(ret)\n  \n}\n\nautoml_models_h2o@leaderboard %>%\n  plot_h2o_performance(newdata = test_tbl, order_by = \"logloss\", \n                       size = 1, max_models = 4)\n```\n:::\n\n\n![](img_chal5/Rplot.png)\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}