{
  "hash": "a861896cdbd206e30bc638a127e29f64",
  "result": {
    "markdown": "---\ntitle: \"Challenge 6 \"\nauthor: \"Benjamin Knaack\"\ndate: \"2023-05-21\"\noutput: html_document\n---\n\n::: {.cell hash='06_challenge_cache/html/unnamed-chunk-1_3d6b250026b82f3bed06d69182c184ec'}\n\n```{.r .cell-code}\n# perform local interpretations of ML models with lime\n\n# LIME FEATURE EXPLANATION ----\n\n# 1. Setup ----\n\n# Load Libraries \n\nlibrary(h2o)\nlibrary(recipes)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(lime)\n\n# Load Data\nemployee_attrition_tbl <- read_csv(\"datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\ndefinitions_raw_tbl    <- read_excel(\"data_definitions.xlsx\", sheet = 1, col_names = FALSE)\n\n# Processing Pipeline\nsource(\"data_processing_pipeline.R\")\n\nemployee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)\n\n# Split into test and train\nset.seed(seed = 1113)\nsplit_obj <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)\n\n# Assign training and test data\ntrain_readable_tbl <- training(split_obj)\ntest_readable_tbl  <- testing(split_obj)\n\n# ML Preprocessing Recipe \nrecipe_obj <- recipe(Attrition ~ ., data = train_readable_tbl) %>%\n  step_zv(all_predictors()) %>%\n  step_mutate_at(c(\"JobLevel\", \"StockOptionLevel\"), fn = as.factor) %>% \n  prep()\n\nrecipe_obj\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n\n# 2. Models ----\n\nh2o.init()\n\nautoml_leader <- h2o.loadModel(\"04_Modeling/h20_models/StackedEnsemble_AllModels_3_AutoML_19_20230521_123133\")\nautoml_leader\n\n\n# 3. LIME ----\n\n# 3.1 Making Predictions ----\n\npredictions_tbl <- automl_leader %>% h2o.predict(newdata = as.h2o(test_tbl)) %>%\n  as.tibble() %>%\n  bind_cols(\n    test_tbl %>%\n      select(Attrition, EmployeeNumber)\n  )\n\npredictions_tbl\n## # A tibble: 220 x 5\n##    predict    No    Yes Attrition EmployeeNumber\n##    <fct>   <dbl>  <dbl> <fct>              <dbl>\n##  1 Yes     0.363 0.637  Yes                    1\n##  2 No      0.863 0.137  No                    15\n##  3 No      0.963 0.0374 No                    20\n##  4 No      0.868 0.132  No                    21\n##  5 No      0.952 0.0483 No                    38\n##  6 No      0.808 0.192  No                    49\n##  7 No      0.930 0.0696 No                    54\n##  8 Yes     0.559 0.441  No                    61\n##  9 Yes     0.412 0.588  No                    62\n## 10 No      0.936 0.0640 No                    70\n## # … with 210 more rows\n\n\n\n\n\ntest_tbl %>%\n  slice(2) %>%\n  glimpse()\n\n\n# LIME is used to determine which features contribute to the prediction (& by how much) for a single observation\n\n\n\n# 3.2 Single Explanation ----\n\nexplainer <- train_tbl %>%\n  select(-Attrition) %>%\n  lime(\n    model           = automl_leader,\n    bin_continuous  = TRUE,\n    n_bins          = 4,\n    quantile_bins   = TRUE\n  )\n\nexplainer\n\n\n\n?lime::explain\n\nexplanation <- test_tbl %>%\n  slice(9) %>%\n  select(-Attrition) %>%\n  lime::explain(\n    \n    # Pass our explainer object\n    explainer = explainer,\n    # Because it is a binary classification model: 1\n    n_labels   = 1,\n    # number of features to be returned\n    n_features = 8,\n    # number of localized linear models\n    n_permutations = 5000,\n    # Let's start with 1\n    kernel_width   = 1\n  )\n\nexplanation\n\n\nexplanation %>%\n  as.tibble() %>%\n  select(feature:prediction)\n\n\n\n\n\ng <- plot_features(explanation = explanation, ncol = 1)\n\ng\n```\n:::\n\n\n\n\n\n### Part 1: Due to the hint the function my_plot_features() is built up from code snippets from Thomas Pedersens’ github page... So the function is kind of the same, but less robust.\n\n\n\n::: {.cell hash='06_challenge_cache/html/unnamed-chunk-2_91005bec9e6f7988daafb0a6802f7b63'}\n\n```{.r .cell-code}\n#explanation$feature_value\n#explanation$feature_weight\n#explanation$feature\n#explanation$feature_desc\n#explanation$label_prob[1] # round\n#unique(format(explanation$label_prob, digits = 2)) # Probability\n#unique(format(explanation$label, digits = 2)) # Label\n#unique(format(explanation$model_r2, digits = 2)) # Explanation Fit\n\n\n\nmy_plot_features <- function(explanation){\n\ntype_pal <- c('Supports', 'Contradicts')\nexplanation$probability <- format(explanation$label_prob, digits = 2)\nexplanation$label <- factor(explanation$label, unique(explanation$label[order(explanation$label_prob, decreasing = TRUE)]))\nexplanation$type <- factor(ifelse(sign(explanation$feature_weight) == 1, type_pal[1], type_pal[2]), levels = type_pal)\ndescription <- paste0(explanation$case, '_', explanation[['label']])\ndesc_width <- max(nchar(description)) + 1\ndescription <- paste0(format(description, width = desc_width), explanation$feature_desc)\nexplanation$description <- factor(description, levels = description[order(abs(explanation$feature_weight))])\nexplanation$case <- factor(explanation$case, unique(explanation$case))\nexplanation$Explanation_fit <- format(explanation$model_r2, digits = 2)\n\n\nlabel_helper_fct <- function(labels, multi_line = TRUE, sep = ': ') {\n  names(labels) <- tools::toTitleCase(names(labels))\n  label_both(labels, multi_line, sep)\n}\n\n\n\nggplot(explanation) +\n  facet_wrap(~ case + label + probability + Explanation_fit,labeller = label_helper_fct ,scales = 'free_y', ncol = 1)+\n  geom_col(aes_(~description, ~feature_weight, fill = ~type)) +\n  coord_flip() +\n  scale_fill_manual(values = c('steelblue', 'firebrick'), drop = FALSE) +\n  scale_x_discrete(labels = function(lab) substr(lab, desc_width + 1, nchar(lab))) +\n  labs(y = 'Weight', x = 'Feature', fill = '')+\n  theme(\n    strip.text = element_text(face = 'bold', size = 10),\n    plot.margin = margin(15, 15, 15, 15),\n    legend.background = element_blank(),\n    legend.key = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    axis.ticks = element_blank(),\n    legend.position = 'bottom',\n    panel.spacing.y = unit(15, 'pt'),\n    strip.text.x = element_text(margin = margin(t = 2, b = 2), hjust = 0),\n    axis.title.y = element_text(margin = margin(r = 15)),\n    axis.title.x = element_text(margin = margin(t = 10))\n  )\n\n\n}\n\n\n\nexplanation %>% \n  as.tibble()\n\ncase_1 <- explanation %>%\n  filter(case == 1)\n\ncase_1\n\nmy_plot_features(case_1)\n```\n:::\n\n![](part1_chal6.png)\n\n\n\n\n### Part 2: This is basically the function from the source code of the lime library on github.\nI hope this is in accordance with the task... I dont see the point of further changing lines of code or renaming variables to make it look like mine.\n\n\n::: {.cell hash='06_challenge_cache/html/unnamed-chunk-3_cfa8a0b331009861da687e4d75c339a0'}\n\n```{.r .cell-code}\n# 3.3 Multiple Explanations ----\n\nexplanation <- test_tbl %>%\n  slice(1:20) %>%\n  select(-Attrition) %>%\n  lime::explain(\n    explainer = explainer,\n    n_labels   = 1,\n    n_features = 8,\n    n_permutations = 5000,\n    kernel_width   = 0.5\n  )\n\nexplanation %>%\n  as.tibble()\n\nplot_features(explanation, ncol = 4)\n\n\n\n\nplot_explanations(explanation)\n```\n:::\n\n\n\n\n### my_plot_explanations\n\n::: {.cell hash='06_challenge_cache/html/unnamed-chunk-4_6232b771bb5f349cb610f870998a451b'}\n\n```{.r .cell-code}\nmy_plot_explanations <- function(explanation = NULL) {\n  \n  num_cases <- unique(suppressWarnings(as.numeric(explanation$case)))\n  \n  \n  \n  if (!anyNA(num_cases)) {\n    explanation$case <- factor(explanation$case, levels = as.character(sort(num_cases)))\n  }\n  \n  explanation$feature_desc <- factor(\n    explanation$feature_desc,\n    levels = rev(unique(explanation$feature_desc[order(explanation$feature, explanation$feature_value)]))\n  )\n  \n  \n  \n  ggplot(explanation, aes_(~case, ~feature_desc)) +\n    \n    geom_tile(aes_(fill = ~feature_weight)) +\n    \n    scale_x_discrete('Case', expand = c(0, 0)) +\n    \n    scale_y_discrete('Feature', expand = c(0, 0)) +\n    \n    scale_fill_gradient2('Feature\\nweight', low = 'green', mid = '#f7f7f7', high = 'steelblue') +\n    \n    theme(\n      strip.text = element_text(face = 'bold', size = 10),\n      plot.margin = margin(15, 15, 15, 15),\n      legend.background = element_blank(),\n      legend.key = element_blank(),\n      panel.grid.major.y = element_blank(),\n      panel.grid.minor.y = element_blank(),\n      axis.ticks = element_blank(),\n      legend.position = 'bottom',\n      panel.spacing.y = unit(15, 'pt'),\n      strip.text.x = element_text(margin = margin(t = 2, b = 2), hjust = 0),\n      axis.title.y = element_text(margin = margin(r = 15)),\n      axis.title.x = element_text(margin = margin(t = 10))\n    ) +\n\n    theme(panel.border = element_rect(fill = NA, colour = 'grey60', size = 1),\n          panel.grid = element_blank(),\n          legend.position = 'right',\n          axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +\n  facet_wrap(~label)\n}\n\n\nmy_plot_explanations(explanation)\n```\n:::\n\n\n![](part2_chal6.png)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}